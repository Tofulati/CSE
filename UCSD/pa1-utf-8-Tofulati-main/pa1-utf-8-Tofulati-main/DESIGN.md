1. Some tradeoffs between UTF-32 and UTF-8 are that for UTF-32, you do not need to worry about the size of each of the codepoints as they are all 4 bytes long, unlike UTF-8. Something that is also useful for UTF-32 that UTF-8 is that you can easily traverse through a string since they are all the same byte size, which makes them more efficient. However, some problems are the UTF-32 is larger in size compared to UTF-8 since all the codepoints are 4 bytes. Something else is that UTF-32 may not be compatible with some systems unless they are able to decode and recognize the UTF-32 unicode. 

2. Some tradeoffs that a leading 10 is useful is the detection of continuation bytes. When doing the PA, I noticed that if the leading 10 bytes were removed, the program would recognize them as special characters (variation) or other ascii values. This is problematic as you may not be able to print the correct character. Another tradeoff is that the program could possibly have issues traversing the bytes since they are unable to recognize whether to read the bytes as a part of the starting byte. Something that could go wrong with programs if the encoding didn't include this restriction would be the possiblity that the program prints out an ASCII value for each of the bytes or special characters. 

Resubmission Question: 
    1. The code point of the 3-byte sequence `11100000 10000000 10100001` is converted to `0000000000100001` which is 33 in decimal. This character is `!` in UTF-8 encoding.
    2. Three other ways that you can encode this character is through UTF-16, and UTF-32. Each of these encoding could be represented in different byte forms through Big Endian and Little Endian. For example in UTF-16, the encoding is `00 81` in Big Endian and `81 00` in Little Endian. Another way is overlong UTF-8 encoding. 
    3. Another character that has exactly three encodings is the character '.'. Which can be represented in UTF-8 as `2E', UTF-16 LE (2E 00) BE (00 2E), and UTF-32 LE (2E 00 00) BE (00 00 2E).
    4. Some problems with having multiple encodings is due to overlong UTF-8 encoding. This is an issue because of how the encoding differs from UTF-8 encoding, as there is an extra hex value added to the beginning of the UTF-8 encoded value. Moreover, overlong UTF-8 encoding would add additional bytes which does result in the original encoding of the character, however its representation is incorrect and may have issues printing the true character. In addition to this, there are memory issues as the character encoding takes up more space, and how there may be issues on how the characters can be passed into a character despite having the wrong representation.